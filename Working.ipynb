{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'train.p'\n",
    "validation_file='valid.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "labels=[x for x in train['labels']]\n",
    "labels.extend([x for x in valid['labels']])\n",
    "labels.extend([x for x in test['labels']])\n",
    "X_train_norm=[]\n",
    "##print(len(valid['labels']))\n",
    "##print(len(test['labels']))\n",
    "##print(len(labels))\n",
    "labels_set=set(labels)\n",
    "##print(len(label_set))\n",
    "## X_train=(X_train-128)/128\n",
    "## X_valid=(X_valid-128)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = len(X_valid)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# TODO: What's the shape of a traffic sign image?\n",
    "image_shape = X_train[0].shape ##(len(train['features'][0]),len(train['features'][0][0]),len(train['features'][0][0][0]))\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(labels_set)\n",
    "##print(X_train[0].shape)\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def normalize(data):\n",
    "    a=0.1\n",
    "    b=0.9\n",
    "    data = data.astype(np.int16)\n",
    "    data=a+data*(b-a)/255\n",
    "    ##data=(data-128)/128\n",
    "    print(data.shape)\n",
    "    return data\n",
    "\n",
    "def im2gray(data):\n",
    "    gray_data=[]\n",
    "    for im in data:\n",
    "        gray=cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "        gray_data.append(gray)\n",
    "    gray_data=np.array(gray_data)\n",
    "    print(gray_data.shape)\n",
    "    ##data=0.2989 *data[:,:,:,0] + 0.5870 * data[:,:,:,1] + 0.1140 * data[:,:,:,2]\n",
    "    plt.imshow(gray_data[len(gray_data)-1],cmap='gray')\n",
    "    plt.savefig('./training_img_gr.jpg')\n",
    "    gray_data=gray_data[...,np.newaxis]\n",
    "    print(gray_data.shape)\n",
    "    return gray_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Data Augmentation] Rotating and adding new images to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "def rotate(image,angle):\n",
    "    rotated = ndimage.rotate(image,angle)\n",
    "    left=0\n",
    "    right=rotated.shape[1]\n",
    "    mid_x=(right-left)/2\n",
    "    left=int(mid_x-16)\n",
    "    right=left+32\n",
    "    up=0\n",
    "    bottom=rotated.shape[0]\n",
    "    mid_y=(bottom-up)/2\n",
    "    up=int(mid_y-16)\n",
    "    bottom=up+32\n",
    "    new_rot=rotated[left:right,up:bottom,:]\n",
    "    return new_rot\n",
    "    \n",
    "##plt.imshow(rotate(X_train[1079],45))\n",
    "\n",
    "lower_bound=1200\n",
    "bins=np.bincount(y_train)\n",
    "augment_x=[]\n",
    "augment_y=[]\n",
    "num_examples = len(X_train)\n",
    "BATCH_SIZE = 128\n",
    "print(\"Augmenting... on \"+str(num_examples)+\" examples\")\n",
    "print()\n",
    "for offset in range(0, num_examples, BATCH_SIZE):\n",
    "    end = offset + BATCH_SIZE\n",
    "    if end>=num_examples:\n",
    "        end=num_examples\n",
    "    for i in range(offset,end):\n",
    "        for ang in range(-15,40,30):\n",
    "            temp=rotate(X_train[i],ang)\n",
    "            augment_x.append(temp)\n",
    "            augment_y.append(y_train[i])\n",
    "    print(\"Finished till \"+str(end)+\" batch\")\n",
    "    \n",
    "'''\n",
    "for i in range(n_train):\n",
    "    for ang in range(10,40,15):\n",
    "        temp=rotate(X_train[i],ang)\n",
    "        np.append(X_train,temp)\n",
    "        np.append(y_train,y_train[i])\n",
    "'''\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "augment_x=np.array(augment_x)\n",
    "augment_y=np.array(augment_y)\n",
    "print(augment_x.shape)\n",
    "print(augment_y.shape)\n",
    "print(\"######################\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train=np.append(X_train,augment_x,axis=0)\n",
    "y_train=np.append(y_train,augment_y,axis=0)\n",
    "bins=np.bincount(y_train)\n",
    "## print(bins)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Gray scaling]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gr=im2gray(X_train)\n",
    "X_valid_gr=im2gray(X_valid)\n",
    "X_test_gr=im2gray(X_test)\n",
    "print(X_train_gr.shape)\n",
    "print(X_valid_gr.shape)\n",
    "print(X_test_gr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing Data\n",
    "Between 0.1 to 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104397, 32, 32, 3)\n",
      "(4410, 32, 32, 3)\n",
      "(104397, 32, 32, 3)\n",
      "(4410, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train=normalize(X_train_gr)\n",
    "X_valid=normalize(X_valid_gr)\n",
    "X_test=normalize(X_test_gr)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x20.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 20), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(20))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x20. Output = 14x14x20.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional.14x14x20  Output = 12x12x40.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 20, 40), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(40))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Convolutional.12x12x40  Output = 10x10x80.\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 40, 80), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(80))\n",
    "    conv3   = tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='VALID') + conv3_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x80. Output = 5x5x80.\n",
    "    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x80. Output = 400.\n",
    "    fc0   = flatten(conv3)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 2000. Output = 200.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(2000, 200), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(200))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    w = tf.Variable(tf.truncated_normal(shape=(200, 120), mean = mu, stddev = sigma))\n",
    "    b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc1, w) + b\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.add(tf.matmul(fc2, fc3_W),fc3_b, name=\"logits\")\n",
    "    \n",
    "    return logits\n",
    "\n",
    "print('Model Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... on 104397 examples\n",
      "\n",
      "Training loss 2.596646621302469\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.760\n",
      "\n",
      "Training loss 0.6027613429084244\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.865\n",
      "\n",
      "Training loss 0.33995004802380185\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "Training loss 0.23456010804667501\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "Training loss 0.18670206516759885\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.941\n",
      "\n",
      "Training loss 0.15656836439155555\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "Training loss 0.12944523934694377\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "Training loss 0.12297662790395712\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.951\n",
      "\n",
      "Training loss 0.10635980921032614\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.963\n",
      "\n",
      "Training loss 0.0966269737152095\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "'''\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "plt.imshow(X_train[56])\n",
    "print(y_train[56])\n",
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1), name=\"x_inp\")\n",
    "y = tf.placeholder(tf.int32, (None), name=\"y_inp\")\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"k_prob\")\n",
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy, name=\"loss_operation\")## loss \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate) \n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1), name=\"correct_prediction\")\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"accuracy_operation\")\n",
    "saver = tf.train.Saver()\n",
    "loss_valid=[]\n",
    "loss_train=[]\n",
    "epochs=[]\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    total_loss = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        loss,accuracy = sess.run([loss_operation,accuracy_operation], feed_dict={x: batch_x, y: batch_y,keep_prob:1.0})        \n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        total_loss += (loss * len(batch_x))\n",
    "    return total_loss/num_examples,total_accuracy / num_examples\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training... on \"+str(num_examples)+\" examples\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            loss,var=sess.run([loss_operation,training_operation], feed_dict={x: batch_x, y: batch_y,keep_prob:0.7})\n",
    "            total_loss += (loss * len(batch_x))\n",
    "        print(\"Training loss \"+str(total_loss/num_examples))\n",
    "        loss_train.append(total_loss/num_examples)\n",
    "        ##train_loss,train_accuracy=evaluate(X_train, y_train)\n",
    "        validation_loss,validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        ##loss_train.append(train_loss)\n",
    "        loss_valid.append(validation_loss)\n",
    "        epochs.append(i)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    plt.plot(epochs,loss_valid,epochs,loss_train)\n",
    "    plt.xlabel('EPOCHS')\n",
    "    plt.ylabel('LOSS')\n",
    "    plt.savefig('./losscurve.jpg')\n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")\n",
    "    test_loss,test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Testing Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12630, 32, 32, 3)\n",
      "(12630,)\n",
      "Model restored.\n",
      "Testing Accuracy = 0.016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './lenet')\n",
    "    print(\"Model restored.\")\n",
    "    test_loss,test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Testing Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 32, 32, 3)\n",
      "(6,)\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27c71f32240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "testing_file = 'test_cust.p'\n",
    "X_test_google=[]\n",
    "y_test_google=[]\n",
    "def customimgread(path,label):\n",
    "    res=cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    y_test_google.append(label)\n",
    "    return res\n",
    "\n",
    "'''\n",
    "x=customimgread('test\\\\2.jpg',1)\n",
    "print(x.shape)\n",
    "plt.imshow(x)\n",
    "'''\n",
    "X_test_google.append(customimgread('test\\\\35.jpg',35))\n",
    "X_test_google.append(customimgread('test\\\\2.jpg',25))\n",
    "X_test_google.append(customimgread('test\\\\3.jpg',33))\n",
    "X_test_google.append(customimgread('test\\\\4.jpg',1))\n",
    "X_test_google.append(customimgread('test\\\\5.jpg',14))\n",
    "X_test_google.append(customimgread('test\\\\rounabout.jpg',40))\n",
    "X_test_google=np.asarray(X_test_google)\n",
    "y_test_google=np.asarray(y_test_google)\n",
    "test_goog=(X_test_google,y_test_google)\n",
    "\n",
    "filehandler = open(testing_file,\"wb\")\n",
    "pickle.dump(test_goog,filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# print(X_test_google.shape)\n",
    "# print(y_test_google.shape)\n",
    "# plt.imshow(t1)\n",
    "\n",
    "\n",
    "testing_file = 'test_cust.p'\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    X_test_cust,y_test_cust = pickle.load(f)\n",
    "\n",
    "print(X_test_cust.shape)\n",
    "print(y_test_cust.shape)\n",
    "plt.imshow(X_test_cust[5])\n",
    "print(y_test_cust[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
